{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning and Decision Making"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laboratory 2: Markov decision problems\n",
    "\n",
    "In the end of the lab, you should submit all code/answers written in the tasks marked as \"Activity n. XXX\", together with the corresponding outputs and any replies to specific questions posed to the e-mail <adi.tecnico@gmail.com>. Make sure that the subject is of the form [&lt;group n.&gt;] LAB &lt;lab n.&gt;.\n",
    "\n",
    "### 1. Modeling\n",
    "\n",
    "Consider once again the gridworld domain described in the Homework and which you modeled using a Markov decision process.\n",
    "\n",
    "<img src=\"maze.png\" width=\"200px\">\n",
    "\n",
    "Recall that:\n",
    "\n",
    "* At each step, the agent may move in any of the four directions -- up, down, left and right. \n",
    "* Movement across a _grey_ cell division succeeds with a $0.8$ probability and fails with a $0.2$ probability. \n",
    "* Movements across colored cell divisions (blue or red) succeed with a $0.8$ probability _but only if the agent has the corresponding colored key_. Otherwise, they fail with probability $1$. \n",
    "* When the movement fails, the agent remains in the same cell. \n",
    "* To get a colored key, the agent simply needs to stand in the corresponding cell. \n",
    "* The goal of the agent is to reach the cell marked with **\"G\"**. \n",
    "\n",
    "**Throughout the lab, use $\\gamma=0.99$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Activity 1.        \n",
    "\n",
    "Implement your Markov decision process in Python. In particular,\n",
    "\n",
    "* Create a list with all the states;\n",
    "* Create a list with all the actions;\n",
    "* For each action, define a `numpy` array with the corresponding transition probabilities;\n",
    "* Define a `numpy`array with the costs. Make sure that:\n",
    "    * The costs lie in the interval [0, 1]\n",
    "    * The cost for standing in goal cell is minimal\n",
    "    * The cost for standing in intermediate cells is maximal\n",
    "\n",
    "The order for the states and actions used in the transition probability and cost matrices should match that in the lists of states and actions. \n",
    "\n",
    "**Note**: Don't forget to import `numpy`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "gamma = 0.99\n",
    "\n",
    "states = [(1,'both'),\n",
    "          (2,'none'), (2,'red'), (2,'both'),\n",
    "          (3,'none'), (3,'red'), (3,'both'),\n",
    "          (4,'none'), (4,'red'), (4,'both'),\n",
    "          (5,'none'), (5,'red'), (5,'both'),\n",
    "          (6,'red'), (6,'both'), ('goal', 'both')]\n",
    "\n",
    "def probs(possible_actions):\n",
    "    probs = np.identity(16)\n",
    "    \n",
    "    for (orig, dest) in possible_actions:\n",
    "        probs[states.index(orig)][states.index(orig)] = 0.2\n",
    "        probs[states.index(orig)][states.index(dest)] = 0.8\n",
    "    \n",
    "    return probs\n",
    "\n",
    "\n",
    "actions = ['up', 'down', 'left', 'right']\n",
    "\n",
    "probs_u = probs([((4,'none'), (2,'none')),\n",
    "                ((4,'red'), (2,'red')),\n",
    "                ((4,'both'), (2,'both')),\n",
    "                ((5,'none'), (3,'none')),\n",
    "                ((5,'red'), (3,'red')),\n",
    "                ((5,'both'), (3,'both')),\n",
    "                ((6,'red'), (4,'red')),\n",
    "                ((6,'both'), (4,'both'))])\n",
    "\n",
    "probs_d = probs([((2,'none'), (4,'none')),\n",
    "                ((2,'red'), (4,'red')),\n",
    "                ((2,'both'), (4,'both')),\n",
    "                ((3,'none'), (5,'none')),\n",
    "                ((3,'red'), (5,'red')),\n",
    "                ((3,'both'), (5,'both')),\n",
    "                ((4,'none'), (6,'red')),\n",
    "                ((4,'red'), (6,'red')),\n",
    "                ((4,'both'), (6,'both'))])\n",
    "\n",
    "probs_r = probs([((1,'both'), (2,'both')),\n",
    "                ((2,'none'), (3,'none')),\n",
    "                ((2,'red'), (3,'red')),\n",
    "                ((2,'both'), (3,'both')),\n",
    "                ((4,'none'), (5,'none')),\n",
    "                ((4,'red'), (5,'red')),\n",
    "                ((4,'both'), (5,'both')),\n",
    "                ((5,'both'), ('goal','both'))])\n",
    "\n",
    "probs_l = probs([((2,'red'), (1,'both')),\n",
    "                ((2,'both'), (1,'both')),\n",
    "                ((3,'none'), (2,'none')),\n",
    "                ((3,'red'), (2,'red')),\n",
    "                ((3,'both'), (2,'both')),\n",
    "                ((5,'none'), (4,'none')),\n",
    "                ((5,'red'), (4,'red')),\n",
    "                ((5,'both'), (4,'both')),\n",
    "                (('goal','both'), (5,'both'))])\n",
    "\n",
    "probabilities = {'up': probs_u, 'down': probs_d, 'right': probs_r, 'left': probs_l}\n",
    "\n",
    "costs = np.ones((len(states), len(actions)))\n",
    "costs[-1] = [0,0,0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prediction\n",
    "\n",
    "You are now going to evaluate a given policy, computing the corresponding cost-to-go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/latex"
   },
   "source": [
    "---\n",
    "\n",
    "#### Activity 2.\n",
    "\n",
    "Describe the policy that, in each state $x$, always moves the agent to the cell closest to the goal (irrespectively of the number of keys in the agent's possession). If multiple such cells exist, the agent should select randomly between the two.\n",
    "\n",
    "For example, suppose that the agent is in cell 2. It should then select randomly between the actions $D$ and $R$. Conversely, suppose that the agent is in cell 4. The knight should then select actions $R$ with probability 1.\n",
    "\n",
    "**Note:** The policy should be described as a vector with as many rows as there are states and as many columns as there are actions, where the entry $(x,a)$ has the probability of selecting action $a$ in state $x$.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         1.        ]\n",
      " [0.         0.5        0.         0.5       ]\n",
      " [0.         0.5        0.         0.5       ]\n",
      " [0.         0.5        0.         0.5       ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.33333333 0.33333333 0.         0.33333333]]\n"
     ]
    }
   ],
   "source": [
    "def action_row(acs):\n",
    "    row = np.zeros((len(actions)))\n",
    "    for action in acs:\n",
    "        row[actions.index(action)] = 1 / len(acs)\n",
    "    \n",
    "    return row\n",
    "\n",
    "\n",
    "policy = np.array([action_row(['right']),\n",
    "                  action_row(['right', 'down']),\n",
    "                  action_row(['right', 'down']),\n",
    "                  action_row(['right', 'down']),\n",
    "                  action_row(['down']),\n",
    "                  action_row(['down']),\n",
    "                  action_row(['down']),\n",
    "                  action_row(['right']),\n",
    "                  action_row(['right']),\n",
    "                  action_row(['right']),\n",
    "                  action_row(['right']),\n",
    "                  action_row(['right']),\n",
    "                  action_row(['right']),\n",
    "                  action_row(['up']),\n",
    "                  action_row(['up']),\n",
    "                  action_row(['right', 'up', 'down'])])\n",
    "\n",
    "print(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Activity 3.\n",
    "\n",
    "Compute the cost-to-go function $J^\\pi$ associated with the policy from Activity 2.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  4.89502117 100.         100.           3.69420073 100.\n",
      " 100.           2.47821842 100.         100.           2.47821842\n",
      " 100.         100.           1.24688279 100.           3.69420073\n",
      "   0.        ]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "P_pi = np.zeros(probs_r.shape)\n",
    "\n",
    "for action_i, action in enumerate(actions):\n",
    "    P_pi += np.diag(policy[:, action_i]).dot(probabilities[action])\n",
    "\n",
    "c_pi = np.zeros((len(states)))\n",
    "\n",
    "for action_i, action in enumerate(actions):\n",
    "    c_pi += np.diag(policy[:, action_i]).dot(costs[:, action_i])\n",
    "    \n",
    "J_pi = np.linalg.inv(np.identity(len(states)) - gamma * P_pi).dot(c_pi)\n",
    "\n",
    "print(J_pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Control\n",
    "\n",
    "In this section you are going to compare value and policy iteration, both in terms of time and number of iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Activity 4\n",
    "\n",
    "Show that the policy in Activity 3 is _not_ optimal: use value iteration to compute $J^*$ and show that $J^*\\neq J^\\pi$. Track the time and the number of iterations taken to compute $J^*$.\n",
    "\n",
    "**Note 1:** Stop the algorithm when the error between iterations is smaller than $10^{-8}$.\n",
    "\n",
    "**Note 2:** You may find useful the function ``time()`` from the module ``time``.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.89502117 10.67823015  6.08086879  3.69420073 11.79196791  7.25193028\n",
      "  2.47821842  9.55043002  7.25193028  2.47821842 10.67823015  8.40839\n",
      "  1.24688279  8.40839     3.69420073  0.        ]\n",
      "Different!\n",
      "29 iterations\n",
      "0.0030927658081054688 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "eps = 10e-8\n",
    "\n",
    "old_J = np.zeros(len(states))\n",
    "err = 1\n",
    "i = 0\n",
    "t_start = time.time()\n",
    "while err > eps:\n",
    "    Qs = [None] * len(actions)\n",
    "    for action_i, action in enumerate(actions):\n",
    "        Qs[action_i] = costs[:, action_i] + gamma * probabilities[action].dot(old_J)\n",
    "    \n",
    "    new_J = np.min(Qs, axis=0)\n",
    "    err = np.linalg.norm(new_J - old_J)\n",
    "    i += 1\n",
    "    old_J = new_J\n",
    "\n",
    "t_end = time.time()\n",
    "\n",
    "print(old_J)\n",
    "print( \"Equal!\" if np.array_equal(old_J,J_pi) else \"Different!\")\n",
    "print(i, \"iterations\")\n",
    "print(t_end - t_start, \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Activity 5\n",
    "\n",
    "Compute once again the optimal policy now using policy iteration. Track the time and number of iterations taken and compare to those of Activity 4.\n",
    "\n",
    "**Note:** If you find that numerical errors affect your computations (especially when comparing two values/arrays) you may use the `numpy` function `isclose` with adequately set absolute and relative tolerance parameters (e.g., $10^{-8}$).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         1.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.5        0.         0.5       ]\n",
      " [0.         0.5        0.5        0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.5        0.         0.5        0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.33333333 0.33333333 0.         0.33333333]]\n",
      "Different!\n",
      "5 iterations\n",
      "0.004802703857421875 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "eps = 10e-8\n",
    "\n",
    "pi = np.ones((len(states), len(actions)))\n",
    "quit = False\n",
    "i = 0\n",
    "t_start = time.time()\n",
    "while not quit:\n",
    "    cpi = np.zeros((len(states)))\n",
    "    Ppi = np.zeros((probs_u.shape))\n",
    "    for action_i, action in enumerate(actions):\n",
    "        cpi += np.diag(pi[:, action_i]).dot(costs[:, action_i])\n",
    "        Ppi += np.diag(pi[:, action_i]).dot(probabilities[action])\n",
    "    \n",
    "    J = np.linalg.inv(np.eye(len(states)) - gamma * Ppi).dot(cpi)\n",
    "    \n",
    "    Qs = [None] * len(actions)\n",
    "    for action_i, action in enumerate(actions):\n",
    "        Qs[action_i] = costs[:, action_i] + gamma * probabilities[action].dot(J)\n",
    "    \n",
    "    \n",
    "    pinew = np.zeros((len(states), len(actions)))\n",
    "    for action_i, action in enumerate(actions):\n",
    "        pinew[:, action_i] = np.isclose(Qs[action_i], np.min(Qs, axis=0), atol=eps, rtol=eps).astype(int)\n",
    "    \n",
    "    pinew = pinew / np.sum(pinew, axis=1, keepdims=True)\n",
    "    \n",
    "    quit = np.isclose(pi, pinew, atol=eps, rtol=eps).all()\n",
    "    pi = pinew\n",
    "    i += 1\n",
    "\n",
    "t_end = time.time()\n",
    "\n",
    "print(pi)\n",
    "print( \"Equal!\" if np.array_equal(policy,pi) else \"Different!\")\n",
    "print(i, \"iterations\")\n",
    "print(t_end - t_start, \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Simulation\n",
    "\n",
    "Finally, in this section you will check whether the theoretical computations of the cost-to-go actually correspond to the cost incurred by an agent following a policy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Activity 6\n",
    "\n",
    "Suppose that the agent is where depicted in Fig. 1, and consider the situations (i) where it has no keys; (ii) where it has only the red key; (iii) where it has both keys. For each of the three situations,  \n",
    "\n",
    "* Generate **100** trajectories of 10,000 steps each, following the optimal policy for the MDP. \n",
    "* For each trajectory, compute the accumulated (discounted) cost. \n",
    "* Compute the average cost over the 100 trajectories.\n",
    "* Compare the resulting value with that computed in Activity 4. \n",
    "\n",
    "** Note:** The simulation may take a bit of time, don't despair ☺️.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 - 5404201204 - 215 - 217- 223 - 224 - 229 - 251 - 270 - 276 - 328 - 366 - 371 - 439 - 487 - 500 - 520 - 538579 - 583 - 594 - 596 - 598 - 631 - 661 - 674 - 675 - 680 - 698 - 772 - 779 - 791 - 811 - 813 815 - 816 - 878 - 945 - 973 - 986 - 994 - 1016 - 1025 - 1088 - 1090 1173 - 1199 - 1220 - 1229 - 1238 - 1438 - 1501 - 1514 - 1531 - 1549 - 1628 - 1660 - 1703 - 1731 - 1763 - 1776 1790 - 1882 - 1915 - 1993 - 2024 - 2104 - 2114 - 2164 - 2212 - 2276 - 2286 - 2310 - 2396 - 2434 - 2437 - 2522 - 2540 - 2581- 2659 - 2664- 2770- 2881 - 2925 - 2964- 2992 - 3103 - 3202- 3214 - 3256 - 3291 - 3325 - 3436 - 3439 - 3470 - 3547 - 3658 - 3769 - 3829 - 3877 - 3880 - 3951 - 3991 - 4032 - 4078 - 4102 - 4213 - 4324 - 4435 - 4532 - 4546 - 4657 - 4768 - 4829 - 4879 - 4990 - 5101 - 5212 - 5323 - 5434 - 5545 - 5606 - 5656 - 5767 - 5878 - 5937 - 5989 - 6100 - 6115 - 6191 - 6211 - 6322 - 6433 - 6544 - 6655 - 6766 - 6877 - 6926 - 6988 - 7099 - 7210 - 7321 - 7432 - 7543 - 7654 - 7765 - 7876 - 7987 - 8031 - 8098 - 8189 - 8209- 8277 - 8280 - 8320 8375 - 8431 - 8542 - 8653 - 8764 - 8875 - 8986 - 9073 - 9097 - 9208 - 9319 - 9430 - 9541 - 9632 - 9652 - 9763 - 9874 - 9985 - 96 - 207 - 318 - 429 - 449 - 540 - 589 - 629 - 651 - 718 - 762 - 873 - 984 - 1095 - 1206 - 1317 - 1428 - 1539 - 1565 - 1650 - 1720 - 1761 - 1872 - 1956 - 1983 - 2039 - 2094 - 2205 - 2269 - 2302 - 2316 - 2359 - 2427 - 2538 - 2643 - 2649 - 2681 - 2760 - 2871 - 2920 - 2982 - 3027 - 3093 - 3204 - 3255 - 3315 - 3426 - 3537 - 3648 - 3730 - 3759 - 3870 - 3910 - 3937 - 3981 - 4092 - 4203 - 4314 - 4337 - 4413 - 4425 - 4509 - 4536 - 4599 - 4647 - 4700 - 4758 - 4806 - 4869 - 4924 - 4980 - 5069 - 5091 - 5199- 5313 - 5396 - 5416- 5424 - 5492- 5535- 5646 - 575258685979 6090 - 6172 6201 - 6305 6312 - 6369 - 6419 6645 - 6739 6756 - 6828 6867 69787200 - 7419 - 8119 - 8261 - 8350 - 8533 - 8608 - 8644 - 8701 - 8755 - 8805 - 8817 - 8842 - 8850 - 8855 - 9088 - 9096 - 9115 - 9147 - 9154 - 9159 - 9165 - 9183 - 9192 - 9199 - 9240 - 9242 - 9246 - 9275 - 9293 - 9310 - 9388 - 9400 - 9421 - 9422 - 9524 - 9532 - 9642 - 9643 - 9721 - 9737 - 9744 - 9750 - 9754 - 9795 - 9865 - 9897 - 9957 - 9975 - 9976 - 67 - 87 - 129 194 - 198 - 260 - 278 - 309 - 387 - 415 - 420 - 520 - 531 - 599 - 600 - 638 - 642- 667 - 745 - 864 - 966 - 975 - 1082 - 1086 - 1137 - 1197 - 1291 - 1308 - 13901406 - 14191441 - 1530 - 1594 1605 - 1628 - 1641 - 1752 - 1836 - 1863 - 1974 - 1994 - 2079 - 2085 - 2196 - 2214- 2291 - 2307 - 2332 - 2380 - 2418 - 2431 - 2433 - 2529 - 2640 - 2739 - 2751 - 2813 - 2862 - 2973 - 3055 - 3084 - 3137 - 3189 - 3195 - 3292 - 3306 - 3417 - 3528 - 3639 - 3750 - 3799 - 3861 - 3972 - 4083 - 4194 - 4197 - 4302 - 4305 - 4416 - 4527 - 4638 - 4749 - 4855 - 4860 - 4971 - 4991- 5015 - 5018 - 5082 - 5101 - 5193 - 5304 - 5415 - 5449 - 5498 - 5526 - 5558 - 5612 - 5637 - 5682 - 5748 - 5859 - 5970 - 6046 - 6081 - 6120 - 6192 - 6303 - 6341 - 6390 - 6414 - 6525 - 6544 - 6636 - 6747 - 6842 - 6858 - 6969 - 7080 - 7191 - 7227 - 7266 - 7302 - 7343 - 7413 7453 - 7524 - 7635 - 7687 - 7746 - 7857 - 7968 - 8076 - 8079 - 8119 - 8190 - 8287 - 8301 - 8412 - 8448 - 8523 - 8634 - 8745 - 8780 - 8853 - 8856 - 8914 - 8967 - 9078 - 9118 - 9189 - 9283 - 93009341 - 9411 - 9522 - 9580 - 9633 - 9744 - 9855 - 9914 - 9966 - 77 - 188 - 299 - 363 - 410 - 521 - 632 - 743 - 854 - 965 - 1076 - 1099 - 1187 - 1232 - 1298 - 1402 - 1409 - 1460 - 1490 - 1520 - 1540 - 1631 - 1708 - 1742 - 1853 - 1941 - 1964 - 2075 - 2100 - 2186 - 2276 - 2297 - 2408 - 2519 - 2630 - 2675 - 2741 - 2852 - 2963 - 3028 - 3074 - 3104 - 3185 - 3296 - 3407 - 3518 - 3629 - 3668 - 3695 - 3740 - 3851 - 3962 - 4051 - 4073 - 4184 - 4295 - 4315 - 4406 - 4517 - 4628 - 4739 - 4850 - 4961 - 50725102 - 5183 - 5221 - 5257 - 5294"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-160-7b16f0e0cb89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0maction_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    406\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_schedule_flush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwritelines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36m_schedule_flush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_schedule_in_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_later\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flush\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_schedule_in_thread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# wake event thread (message content is ignored)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    390\u001b[0m                                  copy_threshold=self.copy_threshold)\n\u001b[1;32m    391\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSocket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_parts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def unit_dist(state):\n",
    "    dist = np.zeros((len(states)))\n",
    "    dist[states.index(state)] = 1\n",
    "    return dist\n",
    "\n",
    "\n",
    "for state_dist in [unit_dist((5, 'none')), unit_dist((5, 'red')), unit_dist((5, 'both'))]:\n",
    "    run_costs = []\n",
    "    for i in range(100):\n",
    "        run_dist = state_dist\n",
    "        cost = 0\n",
    "        for k in range(10000):\n",
    "            print(str(i), '-', str(k), end='\\r', flush=True)\n",
    "            action_i = np.random.choice(len(actions), 1, p = run_dist.dot(pi))[0]\n",
    "            action = actions[action_i]\n",
    "            state = np.random.choice(len(states), 1, p = run_dist.dot(probabilities[action]))[0]\n",
    "            run_dist = unit_dist(states[state])\n",
    "            cost += costs[state][action_i] * gamma ** k\n",
    "        run_costs.append(cost)\n",
    "    print(np.sum(run_costs) / 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
